import asyncio
from dotenv import load_dotenv
from typing import Optional
from contextlib import AsyncExitStack
import json
from openai import OpenAI

from mcp import ClientSession,StdioServerParameters
from mcp.client.stdio import stdio_client
import sys


class MCPClient:
    def __init__(self):
        '''Initialize the MCPClient'''

        self.openai_api_key="sk-blvnnivvsysypkenyyywxaxjtageyowdviqcdzgyzgrqxarx"
        self.base_url="https://api.siliconflow.cn/v1/" 
        self.model="Qwen/Qwen3-32B" 
        # self.openai_api_key="sk-blvnnivvsysypkenyyywxaxjtageyowdviqcdzgyzgrqxarx"
        # self.base_url="https://api.siliconflow.cn/v1/" 
        # self.model="Qwen/Qwen3-8B"
        if not self.openai_api_key:
            raise ValueError("OpenAI API key is not set in the environment variables.")
        #åˆ›å»º OpenAI å®¢æˆ·ç«¯å®ä¾‹
        self.client=OpenAI(api_key=self.openai_api_key, base_url=self.base_url) #OpenAI ç±»: è¿™æ˜¯ OpenAI å®˜æ–¹ Python å®¢æˆ·ç«¯åº“çš„ä¸»è¦ç±»ï¼Œç”¨äºä¸ OpenAI çš„ API è¿›è¡Œäº¤äº’
        self.session: Optional[ClientSession]=None
        self.exit_stack=AsyncExitStack()

    
    async def connect_to_server(self,server_script_path:str):

        
        '''è¿æ¥åˆ°MCPæœåŠ¡å™¨å¹¶åˆ—å‡ºå¯ç”¨çš„å·¥å…·'''
        is_python=server_script_path.endswith('.py')
        if_js=server_script_path.endswith('.js')
        if not (is_python or if_js):
            raise ValueError("Server script must be a Python (.py) or JavaScript (.js) file.")
        
        #ç¡®å®šæ‰§è¡Œå‘½ä»¤python or node
        command="python" if is_python else "node"
        server_params=StdioServerParameters(
            command=command, 
            args=[server_script_path],
            env=None
        )

        #å¯åŠ¨MCPæœåŠ¡å™¨å¹¶å»ºç«‹é€šä¿¡
        stdio_transport=await self.exit_stack.enter_async_context(
            stdio_client(server_params)#ç”¨äºåˆ›å»ºä¸€ä¸ªæ ‡å‡†è¾“å…¥/è¾“å‡ºï¼ˆstdioï¼‰çš„å®¢æˆ·ç«¯ä¼ è¾“å±‚
        )
        self.stdio,self.write=stdio_transport
        self.session=await self.exit_stack.enter_async_context(
            ClientSession(
                self.stdio,
                self.write,
            )
        )

        await self.session.initialize()

        # è·å–å¯ç”¨å·¥å…·åˆ—è¡¨
        response=await self.session.list_tools()
        tools=response.tools
        print("\nå·²è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œæ”¯æŒä»¥ä¸‹å·¥å…·ï¼š",[tool.name for tool in tools])

    async def process_query(self,query:str)->str:
        '''
        ä½¿ç”¨å¤§æ¨¡å‹å¤„ç†æŸ¥è¯¢å¹¶è°ƒç”¨å¯ç”¨çš„MCPå·¥å…·ï¼ˆFunctionï¼‰
        '''
        messages=[{"role":"user","content":query}]
        response=await self.session.list_tools()

        available_tools=[{
            "type":"function",
            "function":{
                "name":tool.name,
                "description":tool.description,
                "input_schema":tool.inputSchema
            }
        }for tool in response.tools]

        response=self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            tools=available_tools
        )

        #å¤„ç†è¿”å›å†…å®¹
        content=response.choices[0]
        if content.finish_reason=="tool_calls":
            #å¦‚æœæ˜¯éœ€è¦ä½¿ç”¨å·¥å…·ï¼Œå°±è§£æå·¥å…·
            tool_call=content.message.tool_calls[0]
            tool_name=tool_call.function.name
            tool_args=json.loads(tool_call.function.arguments)
        
            #æ‰§è¡Œå·¥å…·
            result=await self.session.call_tool(tool_name,tool_args)
            print(f"\n\nğŸŒŸCalling tool {tool_name} with args {tool_args} ....\n\n")

            #å°†æ¨¡å‹è¿”å›çš„è°ƒç”¨çš„toolå’Œtoolæ‰§è¡Œåçš„æ•°æ®å­˜å…¥
            messages.append(content.message.model_dump())
            messages.append({
                "role":"tool",
                "content":result.content[0].text,
                "tool_call_id":tool_call.id
            })

            #å°†ä¸Šé¢ç»“æœè¿”å›ç»™å¤§æ¨¡å‹ç”¨äºç”Ÿäº§æœ€ç»ˆçš„ç»“æœ
            response=self.client.chat.completions.create(
                model=self.model,
                messages=messages
            )
            return response.choices[0].message.content
        return content.message.content

    async def chat_loop(self):
        ''''è¿è¡Œäº¤äº’å¼èŠå¤©å¾ªç¯'''
        print("\nğŸ¤– MCPå®¢æˆ·ç«¯å·²å¯åŠ¨ï¼è¾“å…¥ 'quit' é€€å‡º")

        while True:
            try:
                query= input("\nè¯·è¾“å…¥æ‚¨çš„æŸ¥è¯¢ï¼ˆæˆ–è¾“å…¥ 'quit' é€€å‡ºï¼‰ï¼š")
                if query.lower() == 'quit':
                    print("é€€å‡ºèŠå¤©...")
                    break
                response=await self.process_query(query)
                print(f"\nğŸ¤– OpenAIï¼š{response}")
           
            except Exception as e:
                print(f"å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")

    async def close(self):
        '''å…³é—­MCPå®¢æˆ·ç«¯'''
        await self.exit_stack.aclose()
        print("MCPå®¢æˆ·ç«¯å·²å…³é—­ã€‚")
    
async def main():
    if len(sys.argv) < 2:
        print("ğŸŒŸ Usage: python client.py <path_to_server_srcipt>")
        sys.exit(1)
    client=MCPClient()
    try:
        await client.connect_to_server(sys.argv[1])
        await client.chat_loop()
    finally:
        await client.close()
if __name__ == "__main__":
    import sys
    asyncio.run(main())